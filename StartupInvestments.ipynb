{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w7zM-ycMOKt8",
        "8F1neP2kXHFo",
        "11WGVX1YNsNx",
        "_mLaOuJJOAIZ",
        "rZe0Cpkq_J-4",
        "HxQYTmbNxmnE",
        "tycRpPnmZyUo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/justinas/startup-investments"
      ],
      "metadata": {
        "id": "UNuCY1thPQP2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKHdhn9q7y8L"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XsrSkFj718F"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdMfF46l74PH"
      },
      "outputs": [],
      "source": [
        "# Mount local google drive so this notebook can access it (have to give permission)\n",
        "def mount_drive(drivename):\n",
        "  drive.mount(drivename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2m9SwFK74wj"
      },
      "outputs": [],
      "source": [
        "# Note: Everyone's local environment will need to follow this same directory hierarchy\n",
        "drivename = '/content/drive'\n",
        "kagglefile_directory = '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/KaggleFiles/'\n",
        "\n",
        "mount_drive(drivename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otc4iB1WoPWP"
      },
      "source": [
        "# Load Data / Data Preprocessing (part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read in data as dictionary of data frames\n",
        "2. Replace all nan values with '' empty string"
      ],
      "metadata": {
        "id": "6ljhmlChoZaA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5C--dr7oPWQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn_j8a1eoPWQ"
      },
      "outputs": [],
      "source": [
        "# Replace all nan values with an empty string ''\n",
        "  # Note: I think all the columns with nan values might contain non-numeric values, but I'm not 100% sure\n",
        "   # Put in comment near man function\n",
        "def replace_nan(df, replace_val):\n",
        "    df.fillna(value=replace_val, inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoIO8XBFoPWQ"
      },
      "outputs": [],
      "source": [
        "# Read in csv file as a pandas dataframe\n",
        "def read_csv(filepath):\n",
        "  df = pd.read_csv(filepath, engine=\"python\")\n",
        "  df = replace_nan(df, '')\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMweqEPnoPWQ"
      },
      "outputs": [],
      "source": [
        "''' Creates python dictionary of pandas dataframes (one df per csv file)\n",
        "      Keys are the csv filenames/tables (e.g. 'objects')\n",
        "      Each Value is a corresponding pandas dataframe\n",
        "        Within this dataframe,\n",
        "        Keys are the column names (e.g., domain)\n",
        "        Values are the columns values\n",
        "'''\n",
        "data_dict = {}\n",
        "for filename in os.listdir(kagglefile_directory):\n",
        "    filepath = os.path.join(kagglefile_directory, filename)\n",
        "\n",
        "    key = filename.replace('.csv', '')\n",
        "    value = read_csv(filepath)\n",
        "\n",
        "    data_dict[key] = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXNhOCPXoPWR"
      },
      "source": [
        "###  How to use the data dictionary of data frames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7DG-gbfoPWR"
      },
      "outputs": [],
      "source": [
        "# Data_dict is a dictionary of dataframes\n",
        "print(data_dict.keys())\n",
        "print(data_dict['objects'].keys())\n",
        "print(data_dict['objects']['domain'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHXJ8QLNoPWR"
      },
      "outputs": [],
      "source": [
        "# In each of the 11 tables, the 'id' column uniquely corresponds to the same company\n",
        "  # The exception is the 'objects' file, where the column is titled 'entity_id'\n",
        "print(data_dict['objects']['entity_id'][0])\n",
        "print(data_dict['acquisitions']['id'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCX8LP_noPWR"
      },
      "outputs": [],
      "source": [
        "# The 'object.csv' file is the primary file\n",
        "numcompanies = len(data_dict['objects']['id'])\n",
        "\n",
        "# This is the number of companies with STATUS (our labels) data :\n",
        "print(numcompanies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpBaZavCoPWS"
      },
      "outputs": [],
      "source": [
        "# ...But not all companies listed in the 'objects' table are included across all files\n",
        "print(len(data_dict['objects']['entity_id']))\n",
        "print(len(data_dict['acquisitions']['id']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sachit EDA"
      ],
      "metadata": {
        "id": "w7zM-ycMOKt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EDA Sachit\n",
        "#Acquisitions, IPO's, Investments\n",
        "STARTUPS = (data_dict['objects'].query('entity_type == \"Company\" and status != \"\" and country_code != \"CSS\" and country_code != \"FST\"')\n",
        "            .drop(columns='entity_id')\n",
        "            .drop_duplicates())\n",
        "a = pd.crosstab(STARTUPS['funding_rounds'], STARTUPS['status'])\n",
        "#a <- table(STARTUPS$funding_rounds, STARTUPS$status)\n",
        "#a <- cbind(a, rep(0, nrow(a)))\n",
        "#a = pd.pivot_table(STARTUPS, index='funding_rounds', columns='status',\n",
        "#                   aggfunc=len, fill_value=0, margins=True, margins_name='total of status')\n",
        "#a.loc['total of funding rounds'] = a.sum(axis=0)\n",
        "\n",
        "# Calculate the row and column totals\n",
        "#a['tot_funding_rounds'] = a.sum(axis=1)\n",
        "#a.loc['total of status'] = a.sum(axis=0)\n",
        "\n",
        "# Remove the margin totals\n",
        "#a = a.iloc[:-1, :-1]\n",
        "\n",
        "# Reorder the columns\n",
        "#a = a[['acquired', 'closed', 'ipo', 'operating', 'tot_funding_rounds']]\n",
        "\n",
        "# Reorder the rows\n",
        "#a = a.loc[list(range(1, 16)) + ['total of funding rounds']]\n",
        "\n",
        "# Calculate the total of each column and add it as a row\n",
        "#a.loc['total of status'] = a.sum(axis=0)\n",
        "\n",
        "# Print the resulting table\n",
        "print(a)\n",
        "\n",
        "#No idea how to get rid of the first three tables.\n"
      ],
      "metadata": {
        "id": "8X35aFKpOOT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "# Create the summary table and round the values to 3 decimal places\n",
        "funding_summary = round(pd.Series(STARTUPS['funding_total_usd'][STARTUPS['funding_total_usd'].notnull() & STARTUPS['funding_total_usd'] != 0]).describe(), 3)\n",
        "\n",
        "# Convert the summary series to a DataFrame and transpose it\n",
        "funding_summary_df = pd.DataFrame(funding_summary).T\n",
        "\n",
        "# Display the summary table\n",
        "print(funding_summary_df)"
      ],
      "metadata": {
        "id": "tcaeF9cYtes5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "t = data_dict['acquisitions'].groupby('acquiring_object_id').size().reset_index(name='num_acquisizioni_effettuate')\n",
        "\n",
        "# merge with STARTUPS\n",
        "t = pd.merge(STARTUPS, t, left_on='id', right_on='acquiring_object_id', how='left')[['id', 'num_acquisizioni_effettuate', 'status']]\n",
        "\n",
        "# replace missing values with 0\n",
        "#['num_acquisizioni_effettuate'].fillna(0, inplace=True)\n",
        "t['num_acquisizioni_effettuate_cat'] = pd.Categorical(t['num_acquisizioni_effettuate'])\n",
        "\n",
        "barp = sns.catplot(x='num_acquisizioni_effettuate_cat', kind='count', hue='status', data=t,\n",
        "                   height=5, aspect=2, palette='muted')\n",
        "barp.set(xlabel='Number of acquired companies', ylabel='Count')\n",
        "plt.show()\n",
        "#This is a great representation of the data, but im not able to set it so it has decent zoom/works on percentages instead."
      ],
      "metadata": {
        "id": "5FLerdo0woxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict['objects'].describe()"
      ],
      "metadata": {
        "id": "NRqat7hi0nTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis Shafkat\n",
        "\n",
        "Milestone->degrees->relationship"
      ],
      "metadata": {
        "id": "8F1neP2kXHFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Table: Milestone\")\n",
        "id = data_dict['milestones']['id']\n",
        "print(\"Number of milestones data: \", len(id))\n",
        "print(\"Table: degrees\")\n",
        "id = data_dict['degrees']['id']\n",
        "print(\"Number of degrees data: \", len(id))\n",
        "print(\"Table: Relationship\")\n",
        "id = data_dict['relationships']['id']\n",
        "print(\"Number of relationships data: \", len(id))"
      ],
      "metadata": {
        "id": "sUu2LkAZNjTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df  = data_dict['milestones']\n",
        "\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "kZmFnjt_CCJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df  = data_dict['relationships']\n",
        "\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "MKUbNCZ7C6sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df  = data_dict['degrees']\n",
        "\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "KBX_5AnpC93V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df  = data_dict['objects']\n",
        "\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "19-nRiGwDnK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df2=df.dropna()\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "XYpMjDCIImt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "5q47_7vRMH5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['objects'].keys())"
      ],
      "metadata": {
        "id": "2gld8dmYBlrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['milestones'].keys())"
      ],
      "metadata": {
        "id": "--iaTM-IBhrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "def create_frequency_plot(column, column_name, top_number):\n",
        "\n",
        "  column = remove_values(column, \"\")\n",
        "  column = remove_values(column, \"unaffiliated\")\n",
        "  column = remove_values(column, \"unknown\")\n",
        "\n",
        "  variable_frequency = Counter(column).most_common(top_number)\n",
        "\n",
        "  variables = [var for var, _ in variable_frequency]\n",
        "  counts = [counts for _, counts in variable_frequency]\n",
        "\n",
        "  figure(figsize=(30, 10), dpi=80)\n",
        "  plt.rcParams.update({'font.size': 10})\n",
        "  plt.xticks(rotation='vertical')\n",
        "\n",
        "  plt.bar(variables, counts)\n",
        "  plt.title(str(top_number) + \" Most Common \" + column_name)\n",
        "  plt.ylabel(\"Frequency\", fontsize=12)\n",
        "  plt.xlabel(column_name, fontsize=12)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Lmabg7c8WR9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_values(column, target_val):\n",
        "  new_column = []\n",
        "  count = 0\n",
        "  for i in range(len(column)):\n",
        "    col_val = column[i]\n",
        "    if col_val.lower() != target_val.lower():\n",
        "      new_column.append(col_val)\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  if target_val == \"\":\n",
        "    target_val = \"NaN\"\n",
        "  print(\"Number of \", target_val,  \"values removed: \", count)\n",
        "  return new_column"
      ],
      "metadata": {
        "id": "_bG-zMc8Wkp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Milestones"
      ],
      "metadata": {
        "id": "jlEtJL76PPMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: milestone_at\")\n",
        "milestone_at = data_dict['milestones']['milestone_at']\n",
        "print(\"Number of unique values: \", len(set(milestone_at)))\n",
        "create_frequency_plot(milestone_at, \"milestone_at\", 50)"
      ],
      "metadata": {
        "id": "XAqEiLEzOZFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: milestone_code\")\n",
        "milestone_code = data_dict['milestones']['milestone_code']\n",
        "print(\"Number of unique values: \", len(set(milestone_code)))\n",
        "create_frequency_plot(milestone_at, \"milestone_code\", 50)"
      ],
      "metadata": {
        "id": "ig8ozUtyPoSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: description\")\n",
        "description = data_dict['milestones']['description']\n",
        "print(\"Number of unique values: \", len(set(description)))\n",
        "create_frequency_plot(description, \"description\", 50)"
      ],
      "metadata": {
        "id": "qIZLc3RQP4i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: source_url\")\n",
        "source_url = data_dict['milestones']['source_url']\n",
        "print(\"Number of unique values: \", len(set(source_url)))\n",
        "create_frequency_plot(source_url, \"source_url\", 50)"
      ],
      "metadata": {
        "id": "NFfVn1CnQDon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: milestone_at\")\n",
        "source_description = data_dict['milestones']['source_description']\n",
        "print(\"Number of unique values: \", len(set(source_description)))\n",
        "create_frequency_plot(source_description, \"source_description\", 50)"
      ],
      "metadata": {
        "id": "PK8eZY-rQdDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: created_at\")\n",
        "created_at = data_dict['milestones']['created_at']\n",
        "print(\"Number of unique values: \", len(set(created_at)))\n",
        "create_frequency_plot(created_at, \"created_at\", 50)"
      ],
      "metadata": {
        "id": "w3f0V9lmQm0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: updated_at\")\n",
        "updated_at = data_dict['milestones']['updated_at']\n",
        "print(\"Number of unique values: \", len(set(updated_at)))\n",
        "create_frequency_plot(updated_at, \"updated_at\", 50)"
      ],
      "metadata": {
        "id": "Jn4wJrlwQ4js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Degrees"
      ],
      "metadata": {
        "id": "d6O7KlyeRNfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['degrees'].keys())"
      ],
      "metadata": {
        "id": "V5y-Lns4RP55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: updated_at\")\n",
        "updated_at = data_dict['degrees']['updated_at']\n",
        "print(\"Number of unique values: \", len(set(updated_at)))\n",
        "create_frequency_plot(updated_at, \"updated_at\", 50)"
      ],
      "metadata": {
        "id": "JkrsYccoSNGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: created_at\")\n",
        "created_at = data_dict['degrees']['created_at']\n",
        "print(\"Number of unique values: \", len(set(created_at)))\n",
        "create_frequency_plot(created_at, \"created_at\", 50)"
      ],
      "metadata": {
        "id": "JPqJ93p3SDu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: graduated_at\")\n",
        "graduated_at = data_dict['degrees']['graduated_at']\n",
        "print(\"Number of unique values: \", len(set(graduated_at)))\n",
        "create_frequency_plot(graduated_at, \"graduated_at\", 50)"
      ],
      "metadata": {
        "id": "8ByDxnoXR5vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: institution\")\n",
        "institution = data_dict['degrees']['institution']\n",
        "print(\"Number of unique values: \", len(set(institution)))\n",
        "create_frequency_plot(institution, \"institution\", 50)"
      ],
      "metadata": {
        "id": "t3FMqFQ6RwU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: subject\")\n",
        "subject = data_dict['degrees']['subject']\n",
        "print(\"Number of unique values: \", len(set(subject)))\n",
        "create_frequency_plot(subject, \"subject\", 50)"
      ],
      "metadata": {
        "id": "MaoHuowARk_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: degree_type\")\n",
        "degree_type = data_dict['degrees']['degree_type']\n",
        "print(\"Number of unique values: \", len(set(degree_type)))\n",
        "create_frequency_plot(degree_type, \"degree_type\", 50)"
      ],
      "metadata": {
        "id": "97NOB6niRVgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Relationship"
      ],
      "metadata": {
        "id": "Qv_6C_hySYYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict['relationships'].keys())"
      ],
      "metadata": {
        "id": "rf8HTGGSSa8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column:title\")\n",
        "title = data_dict['relationships']['title']\n",
        "print(\"Number of unique values: \", len(set(title)))\n",
        "create_frequency_plot(title, \"sequence\", 50)"
      ],
      "metadata": {
        "id": "RIeuAnhZTNhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: end_at\")\n",
        "end_at = data_dict['relationships']['end_at']\n",
        "print(\"Number of unique values: \", len(set(end_at)))\n",
        "create_frequency_plot(end_at, \"end_at\", 50)"
      ],
      "metadata": {
        "id": "TekloEzfSqPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: start_at\")\n",
        "start_at = data_dict['relationships']['start_at']\n",
        "print(\"Number of unique values: \", len(set(start_at)))\n",
        "create_frequency_plot(start_at, \"start_at\", 50)"
      ],
      "metadata": {
        "id": "5X5WbKWhSfSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nikhil"
      ],
      "metadata": {
        "id": "11WGVX1YNsNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funding rounds and investments seems to have almost the same data, so I think I did funding rounds as well. Take a look at my tables (Sachit) and if you find it enough you can skip funding rounds."
      ],
      "metadata": {
        "id": "z5SsOcrYNwbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "funding_rounds, funds, *objects*"
      ],
      "metadata": {
        "id": "ejL3NiYmOY1v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvoByjwrM7d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1tXXp9S_M1oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CfSHqnxhNf1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA Caitlin"
      ],
      "metadata": {
        "id": "_mLaOuJJOAIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "People, Offices"
      ],
      "metadata": {
        "id": "-lC1cV9lOjHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_values(column, target_val):\n",
        "  count = 0\n",
        "  for i in range(len(column)):\n",
        "    if column[i] == target_val:\n",
        "      count+=1\n",
        "  print(\"Number of \", target_val,  \"values: \", count)"
      ],
      "metadata": {
        "id": "vGNGEL1ZtEzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_values(column, target_val):\n",
        "  new_column = []\n",
        "  count = 0\n",
        "  for i in range(len(column)):\n",
        "    col_val = column[i]\n",
        "    if col_val.lower() != target_val.lower():\n",
        "      new_column.append(col_val)\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  if target_val == \"\":\n",
        "    target_val = \"NaN\"\n",
        "  print(\"Number of \", target_val,  \"values removed: \", count)\n",
        "  return new_column"
      ],
      "metadata": {
        "id": "zgFkz_EJvJiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "def create_frequency_plot(column, column_name, top_number):\n",
        "\n",
        "  column = remove_values(column, \"\")\n",
        "  column = remove_values(column, \"unaffiliated\")\n",
        "  column = remove_values(column, \"unknown\")\n",
        "\n",
        "  variable_frequency = Counter(column).most_common(top_number)\n",
        "\n",
        "  variables = [var for var, _ in variable_frequency]\n",
        "  counts = [counts for _, counts in variable_frequency]\n",
        "\n",
        "  figure(figsize=(30, 10), dpi=80)\n",
        "  plt.rcParams.update({'font.size': 10})\n",
        "  plt.xticks(rotation='vertical')\n",
        "\n",
        "  plt.bar(variables, counts)\n",
        "  plt.title(str(top_number) + \" Most Common \" + column_name)\n",
        "  plt.ylabel(\"Frequency\", fontsize=12)\n",
        "  plt.xlabel(column_name, fontsize=12)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "grj-MIG10VmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Table: People\")\n",
        "id = data_dict['people']['id']\n",
        "print(\"Number of people: \", len(id))"
      ],
      "metadata": {
        "id": "MoemfQF7vHKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: Birthplaces\")\n",
        "birthplaces = data_dict['people']['birthplace']\n",
        "print(\"Number of unique values: \", len(set(birthplaces)))\n",
        "create_frequency_plot(birthplaces, \"Birthplaces (People)\", 50)"
      ],
      "metadata": {
        "id": "TIGdVR4E6cqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: Affiliation Name\")\n",
        "affiliation_name = data_dict['people']['affiliation_name']\n",
        "print(\"Number of unique values: \", len(set(affiliation_name)))\n",
        "create_frequency_plot(affiliation_name, \"Affiliations (People)\", 50)"
      ],
      "metadata": {
        "id": "J6ps7UbH6fOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Table: Offices\")\n",
        "id = data_dict['offices']['id']\n",
        "print(\"Number of offices: \", len(id))"
      ],
      "metadata": {
        "id": "Wk9CQ80f6h6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column: Region\")\n",
        "region = data_dict['offices']['region']\n",
        "print(\"Number of unique values: \", len(set(region)))\n",
        "create_frequency_plot(region, \"Office Regions\", 50)"
      ],
      "metadata": {
        "id": "Cw6O8AWl1WLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing (part 2)"
      ],
      "metadata": {
        "id": "5S3WAPZS_J-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(From Sachit)\n",
        "\n",
        "Relevant features:\n",
        "1. Degree Subject (CS, Law etc) -> Degrees\n",
        "2. Market segment -> category_code in objects\n",
        "3. Raised_amount_USD -> funding_rounds\n",
        "4. IPO -> IPOâ€™s to connect which companies did IPO\n",
        "\n",
        "These 4 are the most relevant logically + without many garbage values. The rest are less relevant/ more garbage because 4 feels a bit less:\n",
        "\n",
        "5. Number of acquisitions made by the startup ->Acquisitions\n",
        "6. Institution of degree -> Degrees\n",
        "7. Funding total USD -> Objects, lots of 0.0\n",
        "\n",
        "\n",
        "_____"
      ],
      "metadata": {
        "id": "bKElsGcj_J-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(From Caitlin)\n",
        "\n",
        "**NOTE:** The code below is for generating the old train/test splits that did not include the country_code and relationships features.<br>\n",
        "The code for the latter is in my folder.<br>\n",
        "\n",
        "The cleaned feature matrix is NxD.<br>\n",
        "  N is the number of companies<br>\n",
        "  D is the number of features<br>\n",
        "\n",
        "Associated pickle files (in Data/TrainTestSplit/): train_data_2, train_labels_2, test_data_2, test_labels_2<br>\n",
        "\n",
        "**Feature ordering** (index into feature matrix):\n",
        "- 0-41: **category_code** (one-hot encoded) [objects]\n",
        "- 42-206: **country_code** (one-hot encoded) [objects]\n",
        "- 207: **funding_total_usd** (sum of previous raised_amount_usd feature) [objects]\n",
        "- 208: **founded_at** (only the year) [objects]\n",
        "- 209: **funding_rounds** (total number of funding rounds) [objects]<br>\n",
        "- 210: **relationships** (total number of relationships) [objects]<br>\n",
        "- 211: **acquisitions** (count of acquiring_object_id entries) [acquisitions]\n",
        "\n",
        "\n",
        "Notes:\n",
        "1. A one-hot encoding is applied to the original category_code and country_code features.\n",
        "2. The founded_at feature only includes the year, not the month or day.\n",
        "3. Funding rounds: The purpose of creating this feature is to differentiate between companies with \\$0 for funding_total_usd due to having 0 funding rounds and those with one or more funding rounds that raised \\$0.\n",
        "<br>\n",
        "\n",
        "**Feature matrix cleaning**:<br>\n",
        "If one feature was in violation, I removed the entire company from the feature matrix.\n",
        "1. category_code, country_code, founded_at: Removed if null\n",
        "2. funding_total_usd: Removed if the company's funding total was zero AND the number of funding_rounds was greater than zero AND the first_funding_at entry was null\n",
        "\n",
        "**Original Objects table**:<br>\n",
        "N = 196,553 companies<br>\n",
        "operating: 183441<br>\n",
        "acquired: 9394<br>\n",
        "closed: 2584<br>\n",
        "ipo: 1134<br>\n",
        "\n",
        "**Feature matrix** (post-cleaning):<br>\n",
        "N = 64,010 companies<br>\n",
        "operating: 57900<br>\n",
        "acquired: 3898<br>\n",
        "closed: 1601<br>\n",
        "ipo: 611<br>\n",
        "\n",
        "\n",
        "________\n",
        "\n",
        "**INFORMATION ABOUT THE OLD PICKLE FILES**\n",
        "\n",
        "(OLD) Associated pickle files (in Data/TrainTestSplit/): train_data, train_labels, test_data, test_labels<br>\n",
        "\n",
        "(OLD) Feature ordering (index into feature matrix):\n",
        "- 0-41: **category_code** (one-hot encoded) [objects]\n",
        "- 42: **funding_total_usd** (sum of our old raised_amount_usd feature) [objects]\n",
        "- 43: **founded_at** (only the year) [objects]\n",
        "- 44: **total number of acquisitions** (count of acquiring_object_id entries) [acquisitions]\n",
        "- 45: **total number of funding rounds** (count of object_id entries) [funding_rounds]<br>\n",
        "\n",
        "(OLD) Feature matrix (post-cleaning):<br>\n",
        "N = 88,214 companies<br>\n",
        "operating: 81413<br>\n",
        "acquired: 4258<br>\n",
        "closed: 1919<br>\n",
        "ipo: 624<br><br>"
      ],
      "metadata": {
        "id": "JdMJSIee_J-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________\n",
        "\n",
        "Later:\n",
        "\n",
        "More data processing:\n",
        "\n",
        "Definitely: Normalize the numerical variables with respect to the training set\n",
        "\n",
        "Maybe: Identify outliers in funding_total_usd and draised_amount_usd features by removing rows with values += 3*stdev (but this assumes a normal distribution.)\n",
        "\n",
        "____\n",
        "\n",
        "Feature selection:<br>\n",
        "It seems the funding_total_usd is just linear combination of the raised_amount_usd feature, so probably will want to drop the former feature.\n",
        "\n",
        "Feature engineering:<br>\n",
        "Technically, total number of acquisitions and total number of funding round are engineered features."
      ],
      "metadata": {
        "id": "XNZYf-Zg6_du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelocation_featurematrix = '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/FeatureMatrix/'"
      ],
      "metadata": {
        "id": "o8LWUVjV_m1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct the Feature Matrix"
      ],
      "metadata": {
        "id": "rTr4OUL0_J-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels: Obtain ids for each company in the Objects table and their corresponding status\n",
        "objects_table = data_dict['objects']\n",
        "status_labels = list(objects_table.loc[objects_table['entity_type'] == \"Company\", 'status'].values)\n",
        "status_company_ids = list(objects_table.loc[objects_table['entity_type'] == \"Company\", 'id'].values)"
      ],
      "metadata": {
        "id": "iSMmtDHx_J-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature matrix is a list of lists\n",
        "num_features = 5\n",
        "feature_matrix = [[None] * num_features for i in range(len(status_labels))]"
      ],
      "metadata": {
        "id": "qV3wcVCa_J-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature matrix: Incorporate Objects table features\n",
        "objects_table = data_dict['objects']\n",
        "category_codes = list(objects_table.loc[objects_table['entity_type'] == \"Company\", 'category_code'].values)\n",
        "funding_total_usd = list(objects_table.loc[objects_table['entity_type'] == \"Company\", 'funding_total_usd'].values)\n",
        "founded_at = list(objects_table.loc[objects_table['entity_type'] == \"Company\", 'founded_at'].values)\n",
        "\n",
        "for i in range(len(feature_matrix)):\n",
        "  feature_matrix[i][0] = category_codes[i]\n",
        "  feature_matrix[i][1] = funding_total_usd[i]\n",
        "  feature_matrix[i][2] = founded_at[i]"
      ],
      "metadata": {
        "id": "g5alu-mE_J-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature matrix: For each company with a status, compute the total number of acquisitions it has made\n",
        "acquiring_objects_column = data_dict['acquisitions']['acquiring_object_id']\n",
        "acquired_company_count = acquiring_objects_column.value_counts()\n",
        "for i in range(len(status_company_ids)):\n",
        "  company_id = status_company_ids[i]\n",
        "\n",
        "  if company_id in acquired_company_count:\n",
        "    feature_matrix[i][3] = acquired_company_count[company_id]\n",
        "  else:\n",
        "    feature_matrix[i][3] = 0"
      ],
      "metadata": {
        "id": "azJlPy9t_J-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature matrix:\n",
        "  # For each company with a status,\n",
        "  #   compute total number of funding rounds\n",
        "  #   and a list of the amounts raised in usd for each funding round\n",
        "funding_rounds_table = data_dict['funding_rounds']\n",
        "funding_rounds_count = funding_rounds_table['object_id'].value_counts()\n",
        "for i in range(len(status_company_ids)):\n",
        "\n",
        "  company_id = status_company_ids[i]\n",
        "\n",
        "  if company_id in funding_rounds_count:\n",
        "    feature_matrix[i][4] = funding_rounds_count[company_id]\n",
        "  else:\n",
        "    feature_matrix[i][4] = 0"
      ],
      "metadata": {
        "id": "yLN7CN_v_J-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the uncleaned feature matrix\n",
        "import pickle\n",
        "\n",
        "with open(filelocation_featurematrix + 'feature_matrix_uncleaned.pkl', 'wb') as f:\n",
        "  pickle.dump(feature_matrix, f)"
      ],
      "metadata": {
        "id": "AMfSgL2V_J-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the Feature Matrix"
      ],
      "metadata": {
        "id": "rZe0Cpkq_J-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the uncleaned feature matrix\n",
        "import pickle\n",
        "\n",
        "with open(filelocation_featurematrix + 'feature_matrix_uncleaned.pkl', 'rb') as f:\n",
        "  feature_matrix_uncleaned = pickle.load(f)"
      ],
      "metadata": {
        "id": "ULG0g3DT_J-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper data structure:\n",
        "# Make a dictionary that maps each company id to funding_rounds and first_funding_at\n",
        "objects_table = data_dict['objects']\n",
        "objects_table_companies = objects_table.loc[objects_table['entity_type'] == \"Company\"]\n",
        "\n",
        "objects_dict = dict()\n",
        "for i in range(len(objects_table_companies)):\n",
        "  objects_dict[objects_table_companies['id'].values[i]] = [objects_table_companies['funding_rounds'].values[i], objects_table_companies['first_funding_at'].values[i]]\n",
        "\n",
        "print(len(objects_table_companies))"
      ],
      "metadata": {
        "id": "JEiURL-vugLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# If the features pass all the missing value checks,\n",
        "  # add the correspoding company to the cleaned feature matrix\n",
        "  # (see note at top of Data Preprocessing (part 2) section for further details)\n",
        "kept_indices = []\n",
        "for i in range(len(feature_matrix_uncleaned)):\n",
        "\n",
        "  company_id = status_company_ids[i]\n",
        "\n",
        "  # Feature: Category Code\n",
        "  category_code = feature_matrix_uncleaned[i][0]\n",
        "  if category_code == '':\n",
        "    continue\n",
        "\n",
        "  # Feature: Founded At\n",
        "  founded_at = feature_matrix_uncleaned[i][2]\n",
        "  if founded_at == '':\n",
        "    continue\n",
        "\n",
        "  # Feature: Funding total USD\n",
        "  funding_total_usd = feature_matrix_uncleaned[i][1]\n",
        "  if funding_total_usd == 0:\n",
        "    if objects_dict[company_id][0] > 0:\n",
        "      if objects_dict[company_id][1] == '':\n",
        "        continue\n",
        "\n",
        "  kept_indices.append(i)\n",
        "\n",
        "removal_indices = list(set(range(0, len(feature_matrix_uncleaned))) - set(kept_indices))\n",
        "feature_matrix_cleaned = np.delete(feature_matrix_uncleaned, removal_indices, axis=0)\n",
        "status_labels_cleaned = np.delete(status_labels, removal_indices, axis=0)\n",
        "status_company_ids_cleaned = np.delete(status_company_ids, removal_indices, axis=0)"
      ],
      "metadata": {
        "id": "ZL1a-qnR_J-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned feature matrix and corresponding status-related arrays\n",
        "with open(filelocation_featurematrix + 'feature_matrix_cleaned.pkl', 'wb') as f:\n",
        "  pickle.dump(feature_matrix_cleaned, f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_labels_cleaned.pkl', 'wb') as f:\n",
        "  pickle.dump(status_labels_cleaned, f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_company_ids_cleaned.pkl', 'wb') as f:\n",
        "  pickle.dump(status_company_ids_cleaned, f)"
      ],
      "metadata": {
        "id": "wLO4V7DX_J-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Data Preprocessing"
      ],
      "metadata": {
        "id": "HxQYTmbNxmnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the cleaned feature matrix and corresponding status-related arrays\n",
        "import pickle\n",
        "\n",
        "with open(filelocation_featurematrix + 'feature_matrix_cleaned.pkl', 'rb') as f:\n",
        "  feature_matrix_cleaned = pickle.load(f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_labels_cleaned.pkl', 'rb') as f:\n",
        "  status_labels_cleaned = pickle.load(f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_company_ids_cleaned.pkl', 'rb') as f:\n",
        "  status_company_ids_cleaned = pickle.load(f)"
      ],
      "metadata": {
        "id": "bIHyoM4DxxMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip the month and date from the founded_at feature, and convert it to an integer\n",
        "for i in range(len(feature_matrix_cleaned)):\n",
        "  date = feature_matrix_cleaned[i][2]\n",
        "  year = date.split('-', 1)[0]\n",
        "  feature_matrix_cleaned[i][2] = int(year)"
      ],
      "metadata": {
        "id": "45ZZkNVwbL_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding on category_code\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Get all the category codes for all the startups\n",
        "category_codes = np.empty((len(feature_matrix_cleaned), 1), dtype=\"object\")\n",
        "for i in range(len(feature_matrix_cleaned)):\n",
        "  category_codes[i] = feature_matrix_cleaned[i][0]\n",
        "\n",
        "# Create the one hot encoding of category code feature\n",
        "ohencoder = OneHotEncoder()\n",
        "oh_category_codes = ohencoder.fit_transform(category_codes).toarray()\n",
        "print(\"Length of category code array: \", len(oh_category_codes[0]))"
      ],
      "metadata": {
        "id": "9weTlYSQbJFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new feature matrix with expanded category code\n",
        "num_startups = len(feature_matrix_cleaned)\n",
        "one_hot_length = len(oh_category_codes[0])\n",
        "num_features = (len(feature_matrix[0]) - 1) + one_hot_length\n",
        "print(num_startups)\n",
        "print(num_features)\n",
        "feature_matrix_final = np.zeros((num_startups, num_features))\n",
        "for i in range(len(feature_matrix_final)):\n",
        "  # Copy one-hot encoded category code feature vector and split into separate feature entries\n",
        "  feature_matrix_final[i, 0:one_hot_length] = oh_category_codes[i]\n",
        "  # Copy remaining features from the cleaned feature matrix\n",
        "  feature_matrix_final[i, one_hot_length:len(feature_matrix_final[i])] = feature_matrix_cleaned[i][1:len(feature_matrix_cleaned[i])]"
      ],
      "metadata": {
        "id": "LW5iJBmEViy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final feature matrix and corresponding status-related arrays\n",
        "with open(filelocation_featurematrix + 'feature_matrix_final.pkl', 'wb') as f:\n",
        "  pickle.dump(feature_matrix_final, f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_labels_final.pkl', 'wb') as f:\n",
        "  pickle.dump(status_labels_cleaned, f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_company_ids_final.pkl', 'wb') as f:\n",
        "  pickle.dump(status_company_ids_cleaned, f)"
      ],
      "metadata": {
        "id": "E_MLZWqFzCo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "tycRpPnmZyUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems the funding_total_usd is just linear combination of the raised_amount_usd feature, so probably will want to drop the former feature.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nisyk4lrIH2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "rbMZLhYMZyUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data into Train/Test\n",
        "### (Stratified Random Sampling)\n",
        "\n",
        "**Training data**: train_data, train_labels<br>\n",
        "**Test data**: test_data, test_labels<br>"
      ],
      "metadata": {
        "id": "G-sVGVYIArCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelocation_featurematrix = '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/FeatureMatrix/'\n",
        "filelocation_traintestsplit = '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/TrainTestSplit/'"
      ],
      "metadata": {
        "id": "MWPNyYMeCcaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in final startup data (features and labels)\n",
        "import pickle\n",
        "\n",
        "with open(filelocation_featurematrix + 'feature_matrix_final.pkl', 'rb') as f:\n",
        "  feature_matrix_final = pickle.load(f)\n",
        "\n",
        "with open(filelocation_featurematrix + 'status_labels_final.pkl', 'rb') as f:\n",
        "  status_labels_final = pickle.load(f)"
      ],
      "metadata": {
        "id": "8mFYYkDlBlKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the counts of each status label category\n",
        "def print_label_value_counts(status_labels):\n",
        "  unique_status = np.unique(status_labels)\n",
        "  status_counts = np.zeros(len(unique_status))\n",
        "  for i in range(len(unique_status)):\n",
        "    status = unique_status[i]\n",
        "    for j in range(len(status_labels)):\n",
        "      label = status_labels[j]\n",
        "      if label == status:\n",
        "        status_counts[i] += 1\n",
        "    print(\"Count for \", unique_status[i], \": \", int(status_counts[i]))\n",
        "\n",
        "  print(\"Total label count: \", int(sum(status_counts)))"
      ],
      "metadata": {
        "id": "lRlyncOdArC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print status label counts for the final dataset\n",
        "print_label_value_counts(status_labels_final)"
      ],
      "metadata": {
        "id": "etH78Ft6ArC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import math"
      ],
      "metadata": {
        "id": "p_mM75dmBlKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/valid/test split ratios\n",
        "ratio_train = 0.8\n",
        "ratio_test = 0.2\n",
        "\n",
        "# Seed for random generator\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "PEO_QBN1BlKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_startups = len(status_labels_final)\n",
        "startup_ids = list(range(0, number_of_startups))\n",
        "\n",
        "# Get train/valid/test split counts\n",
        "number_of_test = math.ceil(number_of_startups*ratio_test)\n",
        "\n",
        "# Get idxs for train/test split (stratified to resolve label class imbalances)\n",
        "train_ids, test_ids = train_test_split(startup_ids, test_size=number_of_test, random_state=seed, stratify=status_labels_final)"
      ],
      "metadata": {
        "id": "UEtBfjgWBlKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Form train/valid/test splits from unique ids\n",
        "train_data = feature_matrix_final[train_ids]\n",
        "train_labels = status_labels_final[train_ids]\n",
        "\n",
        "test_data = feature_matrix_final[test_ids]\n",
        "test_labels = status_labels_final[test_ids]"
      ],
      "metadata": {
        "id": "thiXH8WsBlKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of startups: \", number_of_startups)\n",
        "\n",
        "# Print status label counts for the splits\n",
        "print(\"\\nTrain labels:\")\n",
        "print_label_value_counts(train_labels)\n",
        "print(\"Percentage of total startups: \", len(train_labels)/number_of_startups)\n",
        "\n",
        "print(\"\\nTest labels:\")\n",
        "print_label_value_counts(test_labels)\n",
        "print(\"Percentage of total startups: \", len(test_labels)/number_of_startups)"
      ],
      "metadata": {
        "id": "21jsQL5hBlKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the training and test feature and label matrices/vectors\n",
        "with open(filelocation_traintestsplit + 'train_data.pkl', 'wb') as f:\n",
        "  pickle.dump(train_data, f)\n",
        "\n",
        "with open(filelocation_traintestsplit + 'train_labels.pkl', 'wb') as f:\n",
        "  pickle.dump(train_labels, f)\n",
        "\n",
        "with open(filelocation_traintestsplit + 'test_data.pkl', 'wb') as f:\n",
        "  pickle.dump(test_data, f)\n",
        "\n",
        "with open(filelocation_traintestsplit + 'test_labels.pkl', 'wb') as f:\n",
        "  pickle.dump(test_labels, f)"
      ],
      "metadata": {
        "id": "LzAHa31p-GgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing (Part 3)\n",
        "\n",
        "Normalize training and test (non-categorical) data"
      ],
      "metadata": {
        "id": "9BHgvBeQ72Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelocation_traintestsplit = '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/TrainTestSplit/'"
      ],
      "metadata": {
        "id": "dYW4NQkwEfe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in training and test feature and label matrices/vectors\n",
        "import pickle\n",
        "\n",
        "with open(filelocation_traintestsplit + 'train_data.pkl', 'rb') as f:\n",
        "  train_data = pickle.load(f)\n",
        "\n",
        "with open(filelocation_traintestsplit + 'test_data.pkl', 'rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "ymmC_x3d70WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "# Normalize train and test data according to train mean and std (non-categorical features)\n",
        "train_mean = np.mean(train_data[:, 42:46], axis=0)\n",
        "train_std = np.std(train_data[:, 42:46], axis=0)\n",
        "\n",
        "train_data_normalized = copy.copy(train_data)\n",
        "test_data_normalized = copy.copy(test_data)\n",
        "\n",
        "train_data_normalized[:, 42:46] = (train_data[:, 42:46] - train_mean)/train_std\n",
        "test_data_normalized[:, 42:46] = (test_data[:, 42:46] - train_mean) / train_std"
      ],
      "metadata": {
        "id": "3DCaFSQ2_6gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the normalized training and test feature vectors\n",
        "with open(filelocation_traintestsplit + 'train_data.pkl', 'wb') as f:\n",
        "  pickle.dump(train_data_normalized, f)\n",
        "\n",
        "with open(filelocation_traintestsplit + 'test_data.pkl', 'wb') as f:\n",
        "  pickle.dump(test_data_normalized, f)"
      ],
      "metadata": {
        "id": "1NJ1rzfcDyuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "KXcz9CYH64uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/CS573_DataMining_FinalProject/Data/TrainTestSplit'\n"
      ],
      "metadata": {
        "id": "JouZJG9-69aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('test_data_5.pkl', 'rb') as f:\n",
        "    test_dataS = pickle.load(f)\n",
        "\n",
        "with open('test_labels_5.pkl', 'rb') as f:\n",
        "    test_labelsS = pickle.load(f)\n",
        "\n",
        "with open('train_data_5.pkl', 'rb') as f:\n",
        "    train_dataS = pickle.load(f)\n",
        "\n",
        "with open('train_labels_5.pkl', 'rb') as f:\n",
        "    train_labelsS = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "Cz8o4oOYWlyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# create a logistic regression model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "# define the hyperparameters of interest and their ranges\n",
        "param_grid = {'C': [0.01, 0.1, 1.0, 10.0],\n",
        "              'penalty': ['l2']}\n",
        "\n",
        "# perform a grid search with 10-fold cross validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=10)\n",
        "grid_search.fit(train_dataS, train_labelsS)\n",
        "\n",
        "# get the best hyperparameters also printing them so you guys can check this makes sense\n",
        "best_params = grid_search.best_params_\n",
        "print('Best hyperparameters:', best_params)\n",
        "\n",
        "# train the final model with the best hyperparameters based on the meeting discussion\n",
        "final_model = LogisticRegression(solver='lbfgs', **best_params, max_iter = 80000)\n",
        "final_model.fit(train_dataS, train_labelsS)\n",
        "\n",
        "# make predictions on the test data\n",
        "test_predictions = final_model.predict(test_dataS)\n",
        "\n",
        "# evaluate the performance on the test set\n",
        "accuracy = accuracy_score(test_labelsS, test_predictions)\n",
        "f1 = f1_score(test_labelsS, test_predictions, average='macro')\n",
        "precision = precision_score(test_labelsS, test_predictions, average='macro')\n",
        "recall = recall_score(test_labelsS, test_predictions, average='macro')\n",
        "conf_mat = confusion_matrix(test_labelsS, test_predictions)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1 score:', f1)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Confusion matrix:')\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "QHbqiBAUXBaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# create a logistic regression model\n",
        "model = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
        "\n",
        "# define the hyperparameters of interest and their ranges\n",
        "param_grid = {'C': [0.01, 0.1, 1.0, 10.0],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "\n",
        "# define class weights\n",
        "class_weights = {0: 1, 1: 2, 2: 5, 3: 10}\n",
        "\n",
        "# perform a grid search with 10-fold cross validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=10)\n",
        "grid_search.fit(train_dataS, train_labelsS)\n",
        "\n",
        "# get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print('Best hyperparameters:', best_params)\n",
        "\n",
        "# train the final model with the best hyperparameters and class weights\n",
        "final_model = LogisticRegression(solver='lbfgs', multi_class='auto', class_weight=class_weights, **best_params, max_iter = 80000)\n",
        "final_model.fit(train_dataS, train_labelsS)\n",
        "\n",
        "# make predictions on the test data\n",
        "test_predictions = final_model.predict(test_dataS)\n",
        "\n",
        "# evaluate the performance on the test set\n",
        "accuracy = accuracy_score(test_labelsS, test_predictions)\n",
        "f1 = f1_score(test_labelsS, test_predictions, average='macro')\n",
        "precision = precision_score(test_labelsS, test_predictions, average='macro')\n",
        "recall = recall_score(test_labelsS, test_predictions, average='macro')\n",
        "conf_mat = confusion_matrix(test_labelsS, test_predictions)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1 score:', f1)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Confusion matrix:')\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "Jy0wNBTbeKXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# create a logistic regression model\n",
        "model = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
        "\n",
        "# define the hyperparameters of interest and their ranges\n",
        "param_grid = {'C': [0.01, 0.1, 1.0, 10.0],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "\n",
        "# randomly undersample the majority class\n",
        "sampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "train_data_resampled, train_labels_resampled = sampler.fit_resample(train_dataS, train_labelsS)\n",
        "\n",
        "# perform a grid search with 10-fold cross validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=10)\n",
        "grid_search.fit(train_data_resampled, train_labels_resampled)\n",
        "\n",
        "# get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print('Best hyperparameters:', best_params)\n",
        "\n",
        "# train the final model with the best hyperparameters on the original training data\n",
        "final_model = LogisticRegression(solver='lbfgs', multi_class='auto', **best_params, max_iter = 80000)\n",
        "final_model.fit(train_data_resampled, train_labels_resampled)\n",
        "\n",
        "# make predictions on the test data\n",
        "test_predictions = final_model.predict(test_dataS)\n",
        "\n",
        "# evaluate the performance on the test set\n",
        "accuracy = accuracy_score(test_labelsS, test_predictions)\n",
        "f1 = f1_score(test_labelsS, test_predictions, average='macro')\n",
        "precision = precision_score(test_labelsS, test_predictions, average='macro')\n",
        "recall = recall_score(test_labelsS, test_predictions, average='macro')\n",
        "conf_mat = confusion_matrix(test_labelsS, test_predictions)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1 score:', f1)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Confusion matrix:')\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "PbRk02nXgL3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shafkat- PCA, normalization, clustering, multi layer perceptron"
      ],
      "metadata": {
        "id": "MdRk1ZFXFGjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('test_data_5.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "\n",
        "with open('test_labels_5.pkl', 'rb') as f:\n",
        "    test_labels = pickle.load(f)\n",
        "\n",
        "with open('train_data_5.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "\n",
        "with open('train_labels_5.pkl', 'rb') as f:\n",
        "    train_labels = pickle.load(f)"
      ],
      "metadata": {
        "id": "mMts214USxEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "sampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "train_data, train_labels = sampler.fit_resample(train_data, train_labels)"
      ],
      "metadata": {
        "id": "_dHcMUe1MW5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf = MLPClassifier(random_state=1, max_iter=100).fit(train_data, train_labels)\n",
        "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(500, 2), random_state=1)\n",
        "clf.fit(train_data, train_labels)"
      ],
      "metadata": {
        "id": "5YU80RnVS0yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(test_data, test_labels)"
      ],
      "metadata": {
        "id": "h4U-SsAsTB0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "# make predictions on the test data\n",
        "test_predictions = clf.predict(test_data)\n",
        "\n",
        "# evaluate the performance on the test set\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "f1 = f1_score(test_labels, test_predictions, average='macro')\n",
        "precision = precision_score(test_labels, test_predictions, average='macro')\n",
        "recall = recall_score(test_labels, test_predictions, average='macro')\n",
        "conf_mat = confusion_matrix(test_labels, test_predictions)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1 score:', f1)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('Confusion matrix:')\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "1NJgtvSnToA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "zeUYKeqMidgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1= train_data[:,42:]"
      ],
      "metadata": {
        "id": "gZoiigEhXrMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of column names\n",
        "column_values = ['funding_total_usd', 'founded_at', 'total_number_of_acquisitions', 'total_number_of_funding_rounds']\n",
        "\n",
        "# creating the dataframe\n",
        "df = pd.DataFrame(data = train1, columns = column_values)"
      ],
      "metadata": {
        "id": "bQEkbyWzYg4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'] = train_labels"
      ],
      "metadata": {
        "id": "rX4EsC5uZOrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.labels.unique()"
      ],
      "metadata": {
        "id": "LWFzbJxDeHrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RBow7Z5-fH55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "E66jwGsVZiJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df.labels)\n",
        "df['categorical_label'] = le.transform(df.labels)"
      ],
      "metadata": {
        "id": "DDMXxlvTaGUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('labels').founded_at.hist(alpha=0.4)"
      ],
      "metadata": {
        "id": "Lti5stPXfgPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df.groupby('labels').funding_total_usd.hist(alpha=0.4)\n",
        "plt.title(\"Funding Total USD vs. Frequency\", color = 'red')\n",
        "plt.legend([\"Operating\", \"Acquired\", \"IPO\", \"Closed\"])"
      ],
      "metadata": {
        "id": "e0IjZFP4foRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('labels').total_number_of_acquisitions.hist(alpha=0.4)"
      ],
      "metadata": {
        "id": "HkXHam7ff1Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('labels').total_number_of_funding_rounds.hist(alpha=0.4)"
      ],
      "metadata": {
        "id": "Xoadw6GVgH5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "%matplotlib inline\n",
        "customcmap = ListedColormap([\"crimson\", \"mediumblue\", \"darkmagenta\", \"yellow\"])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plt.scatter(x=df['founded_at'], y=df['total_number_of_funding_rounds'], s=20000,\n",
        "            c=df['categorical_label'].astype('category'),\n",
        "            cmap = customcmap)\n",
        "ax.set_xlabel(r'x', fontsize=14)\n",
        "ax.set_ylabel(r'y', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wZtH03kzdSaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "%matplotlib inline\n",
        "customcmap = ListedColormap([\"crimson\", \"mediumblue\", \"darkmagenta\", \"yellow\"])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plt.scatter(x=df['funding_total_usd'], y=df['total_number_of_funding_rounds'], s=20000,\n",
        "            c=df['categorical_label'].astype('category'),\n",
        "            cmap = customcmap)\n",
        "ax.set_xlabel(r'x', fontsize=14)\n",
        "ax.set_ylabel(r'y', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZsR4oUMSdFfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "%matplotlib inline\n",
        "customcmap = ListedColormap([\"crimson\", \"mediumblue\", \"darkmagenta\", \"yellow\"])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plt.scatter(x=df['total number of acquisitions'], y=df['total_number_of_funding_rounds'], s=20000,\n",
        "            c=df['categorical_label'].astype('category'),\n",
        "            cmap = customcmap)\n",
        "ax.set_xlabel(r'x', fontsize=14)\n",
        "ax.set_ylabel(r'y', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xwAT-y__eHF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "s3WPt2rc7EIw"
      }
    }
  ]
}